---
title: "S&DS 106 Final Project Report"
author: "Nathan Ahn, Erik Bosen, & Carmen Muniz-Almaguer"
date: "Due 12/22/2021"
output:
  pdf_document: default
  html_document:
    df_print: paged
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo   =FALSE,      ## show or suppress the code
                      include=TRUE ,      ## show or suppress the output
                      message=FALSE,      ## omit messages generated by code
                      warning=FALSE,      ## omit warnings generated by code
                      comment=NA,         ## removes the ## from in front of outputs
                      fig.align="center", ## centers all figures
                      fig.height = 5,     ## set the default height
                      fig.weight = 5      ## set the default width
                      )
library(tidyverse)
library(GGally)
```

## Introduction
In this analysis, we took advantage of a dataset collected by one of our members on occupancy levels of Yale's 14 residential dining halls from spring 2019 through fall 2021 (though we were unfortunately forced to exclude data after March 2020 due to confounding variables related to COVID-19 service disruptions).

Our dining hall occupancy dataset contains over 5.6 million observations including timestamp, dining hall name, and a digit from 0-10 representing the fullness of that dining hall at the given point in time. This crowdedness is our outcome. Yale formerly provided this data through the Yale Dining website, from which it was collected constantly on the server of the [Yale Menus](https://yalemenus.com) app, which is run by one of our members.

We performed a great deal of data cleaning in order to make this observational data more straightforward to analyze. We started by deduplicating our dataâ€”removing sequential observations for the same dining hall with the same crowdedness rating. This allowed us to significantly slim down the size of our data file in order to enable effective collaboration among our team via GitHub.

Then, we created an algorithm to compute summary data for crowdedness across entire meals, grouping observations and calculating weighted averages over time ranges according to historical dining hall opening times.

The second data set we used for our analysis is a New Haven daily weather data set from the National Oceanic and Atmospheric Administrations (NOAA). Through their website, we made a climate data online order. The weather data set begins on 01/02/2018 and ends on 12/05/2021. After filtering out some variables we did not find particularly useful for our analysis, our final data set contained information on: station name, geographic location (New Haven Tweed Airport), date, precipitation, max temperature, and min temperature. 

Having this data, we set about to answer several questions:

* Is there a statistically significant difference between levels of dining hall attendance at different meals (Breakfast, Lunch, Dinner)?
* Is there a difference between attendance to dining halls on weekends vs weekdays?
* Is there a statistically significant decrease in dining hall attendance during "Family Dinner"? (i.e. Sunday nights)
* To what extent do weather conditions affect dining hall attendance?


An overview of your report, including one or so sentences on each of these:


- a non-technical description of what kind of analysis you did and how to interpret the results of the model

      - multiple regression model with the variables 'prcp' 'tmax' and 'tmin' in order to predict occupancy

- a non-technical description of the results of the model and main takeaways.

      - TBD

## Data exploration and visualization
This section will have descriptive statistics and visualizations of the raw data.  Reveal to the reader any interesting relationships in the data, and if you are doing multiple regression, convince the reader that the predictors are related to the outcome. Visualizations are one of the most powerful ways to communicate information to the reader, so it is important to spend time producing clear, descriptive, eye-catching visualizations.

```{r}
ggpairs(d[,c('average_occupancy','date_int','is_weekend_and_not_family_dinner','is_family_dinner','PRCP','TMAX','TMIN')])
```


## Modeling/Analysis
Describe the regression model(s) used or the analysis that was performed. For each regression model, discuss

- any assumptions that are made
- the observations, the predictors, and the outcome (the rows of your data, the columns of your data, and which column will be $y$)
- what the coefficients mean and how this is related to your problem
- appropriate measures of the performance of the model, such as adjusted R^2
- whether or not you think the model is appropriate for this kind of data, and why
- how easy/hard it is to interpret the results and explain them to either a technical or non-technical audience. For example, do the coefficients have the expected sign? Are the sizes (magnitudes) of the coefficients reasonable, and can you put them in real world terms?

```{r}
d <- read.csv("combined.csv")
d <- d %>%
  mutate(
    is_weekend_and_not_family_dinner = ifelse(is_weekend==1,ifelse(is_family_dinner==0,1,0),0),
  )
d_formatted <- d %>%
  select(average_occupancy, is_family_dinner, is_weekend, name) %>%
  mutate(
    is_family_dinner = ifelse(is_family_dinner==1,"True","False"),
    is_weekend = ifelse(is_weekend==1,"True","False")
  )
```

```{r}
#Comparing occupancy of meals
ggplot(d, aes(x=factor(name, levels=c("Breakfast", "Lunch", "Dinner")), y=average_occupancy)) +
  geom_boxplot() +
  xlab("Meal")
print("Breakfast")
summary(d %>% filter(name=="Breakfast") %>% select(average_occupancy))
print("Lunch")
summary(d %>% filter(name=="Lunch") %>% select(average_occupancy))
print("Dinner")
summary(d %>% filter(name=="Dinner") %>% select(average_occupancy))
```

```{r}
#Comparing occupancy of weekend dinners
ggplot(d_formatted, aes(x=factor(is_weekend, levels=c("False","True")), y=average_occupancy)) +
  geom_boxplot() +
  xlab("Is Weekend")
print("Is Not Weekend")
summary(d_formatted %>% filter(is_weekend=="False") %>% select(average_occupancy))
print("Is Weekend")
summary(d_formatted %>% filter(is_weekend=="True") %>% select(average_occupancy))
```

```{r}
d_formatted_dinner_only <- d_formatted %>%
  filter(name=="Dinner")
#Comparing occupancy of family dinner to other dinners
ggplot(d_formatted_dinner_only, aes(x=factor(is_family_dinner, levels=c("False","True")), y=average_occupancy)) +
  geom_boxplot() +
  xlab("Is Family Dinner")

print("Is Not Family Dinner")
summary(d_formatted_dinner_only %>% filter(is_family_dinner=="False") %>% select(average_occupancy))
print("Is Family Dinner")
summary(d_formatted_dinner_only %>% filter(is_family_dinner=="True") %>% select(average_occupancy))
```

```{r}
m1 = lm(average_occupancy ~ name + date_int + is_weekend_and_not_family_dinner + is_family_dinner + TMIN, data=d)
summary(m1)
```


For other kinds of analysis, what you give is highly dependent on the type of analysis you do. But in general, talk about assumptions, if they are appropriate, how they might not be appropriate, and why you chose this type of analysis.

## Visualization and interpretation of the results
Create visualizations of the results, focusing on visualizations that

- help describe aspects of the results that have real-world interpretation
- help the reader understand how the model addresses the problem you are studying.

      -have graph of occupancy from earlier but w/ multiple regression model on top in order to answer the         above two questions?

**Visualizations are one of the most powerful ways to communicate information to the reader, so it is important to spend time producing clear, descriptive, eye-catching visualizations.**

Discuss the results of the model or models you chose, and describe how they are related to the problem statement or question that you were trying to answer in the project.

If you build multiple models or perform multiple types of analysis, compare the measures of performance and the ease of interpretability across models or types of analysis, stating which model or models performed best, and which model or models were most interpretable.  Finally, decide which model or type of analysis is best for your particular problem based on some combination of performance and interpretability.

## Conclusions and recommendations
A few sentences stating conclusions, recommendations, and ideas for future work and improvements.

-conclusions:
-recommendations: ?
-ideas for future work: 
-improvements: use hourly or sub-hourly weather data rather than daily weather data to be able to better calculate the correlation between varying weather and dning hall occupancy
